% Chapter 2: Related Work
% Master's Thesis - Yifeng
% Draft Version 1.0 - FRAMEWORK ONLY

\chapter{Related Work}\label{ch:related-work}

This chapter reviews prior work across four areas relevant to our research: retrieval-augmented generation systems, graph-based retrieval methods, multi-hop and temporal reasoning benchmarks, and legal document analysis.

% ============================================
% 2.1 RAG Evolution
% ============================================
\section{Retrieval-Augmented Generation}\label{sec:rag-evolution}

Retrieval-Augmented Generation (RAG) emerged as a paradigm for enhancing large language models with external knowledge~\cite{lewis2020retrieval}. The core insight is that while LLMs encode broad knowledge through pretraining, they struggle with domain-specific information, recent events, and verifiable factual retrieval. RAG addresses these limitations by retrieving relevant documents from external corpora before generation, grounding model outputs in retrieved evidence.

Recent advances extend RAG to urban and geographic applications. \textcite{mai2024ge} introduced Spatial RAG for geographic entity matching and multi-hop spatial reasoning, demonstrating improved performance on location-based queries. However, existing RAG systems primarily focus on semantic similarity between queries and documents, which proves insufficient for complex reasoning tasks requiring multi-hop inference across structured relationships.

\subsection{Vector-Based Retrieval}

Traditional RAG systems employ dense retrieval using learned embeddings~\cite{karpukhin2020dense}. Documents and queries are encoded into high-dimensional vectors via neural encoders (e.g., BERT-based models), and retrieval operates through nearest neighbor search in embedding space. This approach captures semantic similarity effectively---queries about ``property restrictions'' retrieve documents mentioning ``deed covenants'' even without exact keyword overlap.

However, vector retrieval exhibits fundamental limitations for structured reasoning:

\begin{itemize}
    \item \textbf{Multi-hop inference failure}: Vector similarity measures direct semantic overlap between query and individual documents, but cannot chain reasoning across multiple documents. A query like ``Which properties restricted in the 1920s are near current transit stations?'' requires connecting temporal deed information with contemporary geographic data---a connection invisible to embedding similarity.
    
    \item \textbf{Relationship information loss}: Embeddings collapse structured relationships (``Property A is 0.5 miles from Property B'', ``Deed X was recorded 3 years before Deed Y'') into distributed representations, making explicit relationship traversal impossible.
    
    \item \textbf{Temporal reasoning limitations}: While embeddings may capture temporal context through language, they provide no mechanism for explicit temporal comparison, ordering, or duration calculation required for historical analysis.
\end{itemize}

\subsection{Hybrid Retrieval Approaches}

Recognizing vector retrieval's limitations, hybrid approaches combine sparse (keyword-based) and dense (embedding-based) retrieval. A common pattern uses BM25 for lexical matching alongside neural embeddings, fusing results through learned reranking~\cite{gao2021rethink}. This addresses vocabulary mismatch between queries and documents while preserving exact keyword matching benefits.

Hybrid methods improve recall and precision for keyword-rich domains like legal documents, where specific terminology matters. However, they do not fundamentally address structured reasoning limitations---both sparse and dense retrieval operate on isolated documents without explicit relationship modeling.

\subsection{Limitations for Complex Reasoning}

Empirical studies demonstrate vector RAG's failures on multi-hop reasoning. \textcite{tang2024multihoprag} showed that standard RAG achieves only 38\% accuracy on MultiHop-RAG benchmark questions requiring evidence synthesis from 2+ documents, compared to 67\% for specialized multi-hop methods. The gap widens for queries with explicit relationship constraints---``entities connected through exactly two intermediaries'' or ``events occurring within 5 years of each other.''

For spatio-temporal historical document analysis, these limitations are acute:
\begin{itemize}
    \item Queries like ``properties within 2 miles of each other with covenants recorded in the same year'' require both spatial relationship traversal and temporal constraint checking---operations absent from vector similarity.
    \item Longitudinal analysis (``how did covenant language evolve over decades?'') requires explicit temporal ordering and comparison across time periods.
    \item Causal reasoning (``which earlier deeds influenced later subdivision restrictions?'') requires relationship directionality and temporal precedence---information lost in embeddings.
\end{itemize}

These systematic failures motivate graph-based retrieval approaches that explicitly model relationships as first-class entities.


% ============================================
% 2.2 Graph RAG Methods  
% ============================================
\section{Graph-Enhanced Retrieval}\label{sec:graph-rag-methods}

Graph-enhanced retrieval addresses vector RAG's limitations by explicitly modeling entities and their relationships as knowledge graphs (KGs). This enables traversing multi-hop paths, applying relational constraints, and reasoning about structured information. Recent work demonstrates substantial improvements over vector retrieval for complex queries requiring relationship understanding.

\subsection{Microsoft GraphRAG}

\textcite{edge2024graphrag} introduced GraphRAG, which constructs entity knowledge graphs from text corpora and applies community detection to organize entities hierarchically. The system generates summaries at multiple levels of abstraction, enabling both global queries (``what are the main themes across all documents?'') and local queries (``what is known about specific entity X?'').

Key innovations include:
\begin{itemize}
    \item \textbf{Entity-relationship extraction}: LLM-based extraction identifies entities and relationships from unstructured text, building a structured graph representation.
    \item \textbf{Community detection}: Leiden algorithm partitions graphs into communities representing thematic clusters.
    \item \textbf{Hierarchical summarization}: Summaries generated at community level provide abstract context for answering broad queries.
\end{itemize}

GraphRAG demonstrated 70--80\% win rates compared to baseline RAG on global sensemaking queries in news and podcast domains. However, it imposes significant computational costs ($\sim$\$100--\$500 per corpus for LLM-based extraction and summarization), limiting applicability to resource-constrained settings.

\subsection{LightRAG}

\textcite{guo2025lightrag} proposed LightRAG to address GraphRAG's computational expense. LightRAG achieves comparable accuracy at approximately 6$\times$ lower cost through two key optimizations:

\begin{itemize}
    \item \textbf{Dual-level retrieval}: Combines entity-level retrieval (similar to GraphRAG) with keyword-based chunk retrieval, reducing dependency on expensive graph traversal.
    \item \textbf{Efficient graph construction}: Uses lightweight entity extraction with deduplication, avoiding costly LLM calls for every entity relationship.
\end{itemize}

Evaluations on legal document corpora show LightRAG achieves 80\%+ accuracy while reducing costs from \$500 to $\sim$\$80 per corpus. This efficiency makes graph-enhanced retrieval more practical for production deployment, particularly relevant for our historical deed analysis where corpus size is substantial but budgets are limited.

\subsection{HippoRAG}

\textcite{gutierrez2024hipporag} introduced HippoRAG, inspired by the hippocampus's role in human memory retrieval. The system constructs personalized knowledge graphs that integrate retrieved passages with existing knowledge through LLM-based entity linking and relationship extraction.

Key contributions include:
\begin{itemize}
    \item \textbf{Neurobiologically-inspired indexing}: Mimics hippocampal indexing by storing passages as interconnected memory traces rather than isolated vectors.
    \item \textbf{Multi-hop traversal}: Explicit graph traversal enables answering questions requiring synthesis across 2--3 reasoning hops.
    \item \textbf{Cost efficiency}: Achieves 20\% improvement over iterative retrieval approaches at 10--30$\times$ lower cost by avoiding repeated LLM calls for intermediate retrieval steps.
\end{itemize}

HippoRAG demonstrates particular strength on multi-hop question answering benchmarks like MuSiQue, where it outperforms both standard RAG and iterative retrieval methods. This makes it relevant for our covenant analysis, where queries often require connecting deed information across multiple properties and time periods.

\subsection{Other Approaches}

Several other graph-enhanced retrieval systems have emerged recently:

\begin{itemize}
    \item \textbf{SubgraphRAG}~\cite{subgraphrag2025}: Focuses on extracting relevant subgraphs centered on query-related entities, then reasoning over the subgraph structure. Particularly effective for queries with explicit relationship constraints.
    
    \item \textbf{Neo4j GraphRAG}: Commercial implementation integrating Neo4j graph database with LLM query interfaces. Provides production-ready infrastructure but requires substantial graph database expertise and maintenance.
    
    \item \textbf{G-Retriever}~\cite{gretriever2024}: Graph neural network-based retrieval combining structural and semantic information. Shows promise on knowledge graph completion tasks but limited evaluation on end-to-end QA.
\end{itemize}

Table~\ref{tab:graph-rag-comparison} summarizes key differences among these approaches.

\begin{table}[t]
\caption{Comparison of graph-enhanced retrieval systems}\label{tab:graph-rag-comparison}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{System} & \textbf{Cost} & \textbf{Multi-hop} & \textbf{Setup Complexity} & \textbf{Domain} \\
\midrule
Microsoft GraphRAG & High & Strong & Medium & General \\
LightRAG & Medium & Strong & Low & Legal/Structured \\
HippoRAG & Low & Very Strong & Medium & Multi-hop QA \\
SubgraphRAG & Medium & Very Strong & High & KG-rich domains \\
Neo4j GraphRAG & Variable & Strong & High & Enterprise \\
\bottomrule
\end{tabular}
\end{table}


% ============================================
% 2.3 Multi-Hop and Temporal QA
% ============================================
\section{Multi-Hop Reasoning and Temporal Question Answering}\label{sec:multihop-temporal}

Multi-hop reasoning requires synthesizing information from multiple sources to answer complex queries. Unlike single-hop retrieval (``What is the covenant language in Deed 123?''), multi-hop queries necessitate chaining facts (``Which properties within 1 mile of each other had identical covenant language recorded within the same year?''). Temporal reasoning adds additional complexity by requiring explicit temporal constraint checking, ordering, and duration calculation.

These capabilities are essential for historical document analysis, where understanding patterns requires connecting information across documents, time periods, and geographic regions.

\subsection{Multi-Hop QA Benchmarks}

Several benchmarks evaluate multi-hop reasoning capabilities:

\begin{itemize}
    \item \textbf{HotpotQA}~\cite{yang2018hotpotqa}: Introduced explicit multi-hop requirements by constructing questions requiring reasoning over 2 Wikipedia articles. Includes supporting fact annotations enabling intermediate reasoning evaluation. Baseline RAG systems achieve only $\sim$45\% F1, while specialized multi-hop methods reach $\sim$70\% F1.
    
    \item \textbf{MuSiQue}~\cite{trivedi2022musique}: Addresses shortcut reasoning in HotpotQA by ensuring questions are unanswerable from single passages. Requires genuine multi-hop inference rather than shallow pattern matching. Performance gap between single-hop and multi-hop systems widens to 30+ F1 points.
    
    \item \textbf{MultiHop-RAG}~\cite{tang2024multihoprag}: First benchmark explicitly designed for evaluating RAG systems on multi-hop queries. Includes queries requiring 2--4 hops with controlled evidence corpus. Shows standard RAG achieves only 38\% accuracy versus 67\% for graph-enhanced methods.
\end{itemize}

These benchmarks establish that multi-hop reasoning remains a fundamental challenge for retrieval systems, with graph-based approaches showing systematic advantages over vector similarity methods.

\subsection{Temporal Knowledge Graph QA}

Temporal reasoning introduces additional complexity beyond multi-hop inference. Temporal QA requires:

\begin{itemize}
    \item \textbf{Temporal constraint checking}: Filtering facts by time validity (``events in the 1920s'')
    \item \textbf{Temporal ordering}: Understanding event sequences (``before/after'' relationships)
    \item \textbf{Duration calculation}: Computing time intervals (``within 5 years of each other'')
    \item \textbf{Temporal aggregation}: Summarizing patterns over time periods (``trends across decades'')
\end{itemize}

Key benchmarks and methods include:

\begin{itemize}
    \item \textbf{CronKGQA}~\cite{saxena2021cronkgqa}: Temporal knowledge graph QA requiring reasoning over time-varying facts. Demonstrates that adding temporal dimensions reduces standard KG-QA accuracy by 15--20 points, highlighting the difficulty.
    
    \item \textbf{TempoQR}~\cite{jia2022tempqr}: Focuses on temporal relation extraction and reasoning. Shows that explicit temporal relation modeling significantly outperforms implicit temporal understanding through language models.
    
    \item \textbf{EXAQT}~\cite{pramanik2021exaqt}: Introduces complex temporal reasoning requiring both ``implicit'' temporal knowledge (inferred from context) and ``explicit'' timestamps. Achieves strong results through structured temporal constraint propagation.
\end{itemize}

These works establish the importance of explicit temporal modeling for time-sensitive domains like historical research, where temporal relationships are central to analysis.

\subsection{Spatio-Temporal Reasoning}

Spatio-temporal reasoning combines geographic and temporal constraints---a critical capability for historical property analysis. Queries like ``properties within 2 miles that were restricted within the same year'' require both spatial distance calculation and temporal constraint checking.

Prior work in this area is limited:

\begin{itemize}
    \item \textbf{Spatial RAG}~\cite{mai2024ge}: Addresses geographic entity matching and spatial relationship understanding, but focuses primarily on contemporary geography rather than historical spatio-temporal patterns.
    
    \item \textbf{SSTKG}: Spatio-temporal knowledge graphs for urban computing, primarily focused on transportation and mobility patterns rather than historical document analysis.
    
    \item \textbf{GeoQA}: Geographic question answering on maps and spatial relationships, but limited temporal reasoning capabilities.
\end{itemize}

\textbf{Research Gap}: No prior work systematically evaluates graph-enhanced retrieval for spatio-temporal reasoning over historical legal documents. Existing benchmarks focus either on multi-hop reasoning without spatial constraints, or spatial reasoning without temporal dimensions. Our work addresses this gap by evaluating Graph RAG versus Vector RAG on queries requiring integrated spatio-temporal reasoning over historical deed records.


% ============================================
% 2.4 Legal/Historical Document Analysis
% ============================================
\section{Legal and Historical Document Analysis}\label{sec:legal-docs}

Legal and historical document analysis presents unique challenges: specialized terminology, archaic language, variable document quality, and domain-specific reasoning patterns. Natural language processing for these domains requires both technical solutions (OCR, entity extraction) and domain adaptation (legal reasoning, historical context).

\subsection{Legal NLP Systems}

Legal NLP has developed specialized models and benchmarks:

\begin{itemize}
    \item \textbf{Legal-BERT}~\cite{chalkidis2020legalbert}: Domain-specific BERT model pretrained on legal corpora (case law, statutes, contracts). Shows substantial improvements over general-purpose BERT on legal text understanding tasks, particularly for terminology-heavy applications.
    
    \item \textbf{LexGLUE}~\cite{chalkidis2022lexglue}: Comprehensive benchmark for legal language understanding covering contract analysis, case outcome prediction, and statutory reasoning. Establishes baseline performance levels and common evaluation protocols.
    
    \item \textbf{Contract analysis systems}: Commercial and research systems for automated contract review, clause extraction, and obligation identification. Relevant to deed analysis as deeds function as property transfer contracts with embedded restrictions.
\end{itemize}

These systems demonstrate the value of domain specialization---legal language's unique characteristics (formulaic phrasings, Latin terms, complex sentence structure) benefit from targeted model development rather than relying solely on general-purpose NLP.

\subsection{Historical Document Processing}

Historical documents compound legal text challenges with additional technical issues:

\begin{itemize}
    \item \textbf{OCR degradation}: Faded ink, paper damage, and inconsistent scanning quality reduce OCR accuracy. While modern OCR achieves 98\%+ accuracy on clean contemporary documents, historical document accuracy often drops to 70--85\%.
    
    \item \textbf{Archaic language}: Historical texts employ obsolete terminology, spelling variants, and grammatical constructions absent from modern training corpora. Phrases like ``heirs and assigns forever'' or ``subject to restrictions hereinafter set forth'' require historical linguistic knowledge.
    
    \item \textbf{Handwritten annotations}: Many historical deeds contain handwritten marginalia, corrections, or signatures that challenge OCR systems trained primarily on typewritten text.
\end{itemize}

\textbf{Stanford STARA Project}: The Stanford AREA project (Automated Records Extraction and Analysis) demonstrated large-scale historical document processing for archival research. Their work on extracting structured data from historical census records and immigration documents established methodological precedents for our deed analysis pipeline---particularly the importance of validation against ground truth and iterative error correction.

\subsection{Racial Covenant Research}

Several projects have pioneered racial covenant documentation:

\begin{itemize}
    \item \textbf{Mapping Prejudice (University of Minnesota)}: The most comprehensive covenant mapping effort, documenting 40,000+ covenants in Minneapolis-St.~Paul through volunteer labor~\cite{mapping_prejudice}. Developed the ``Deed Machine'' data processing tool and established best practices for covenant identification and verification. However, their approach relies heavily on manual review, limiting scalability.
    
    \item \textbf{Segregated Seattle}: Documents 400+ covenants across King County, Washington, through community-based research. Demonstrates the educational value of covenant mapping for public understanding of segregation history.
    
    \item \textbf{Stanford RegLab Santa Clara County Project}: Automated covenant detection across 5.2 million deed pages using fine-tuned language models~\cite{suranisuzgun2024}. Achieved \$258 cost versus \$1.4M for manual review. Our work builds directly on their \texttt{mistral-rrc} model for covenant language detection.
    
    \item \textbf{Massachusetts Covenants Project}: Manually mapped 570 covenants statewide, establishing ground truth for our pipeline validation. Identified the scalability challenge motivating automated approaches.
\end{itemize}

\textbf{Research Gap}: While these projects demonstrate covenant documentation's importance, none systematically evaluate how automated extraction outputs should be organized for complex analytical queries. Our work addresses this by comparing graph-based versus vector-based knowledge organization for enabling multi-hop spatio-temporal reasoning over covenant data.


% ============================================
% 2.5 Summary and Positioning
% ============================================
\section{Summary and Research Gap}

This chapter reviewed four research areas informing our work: RAG evolution, graph-enhanced retrieval, multi-hop and temporal reasoning, and legal/historical document analysis.

\paragraph{Key Insights.}
\begin{itemize}
    \item Vector-based RAG exhibits systematic failures on multi-hop reasoning and structured constraint checking (Section~\ref{sec:rag-evolution}).
    \item Graph-enhanced retrieval methods (GraphRAG, LightRAG, HippoRAG) demonstrate 20--40\% improvements on multi-hop benchmarks through explicit relationship modeling (Section~\ref{sec:graph-rag-methods}).
    \item Temporal and spatio-temporal reasoning remain underexplored, particularly for historical document analysis (Section~\ref{sec:multihop-temporal}).
    \item Legal and historical document processing has established technical capabilities (OCR, entity extraction) but lacks systematic evaluation of knowledge organization strategies (Section~\ref{sec:legal-docs}).
\end{itemize}

\paragraph{Research Gap.}
No prior work systematically evaluates graph-enhanced versus vector-based retrieval for spatio-temporal reasoning over historical legal documents. Existing research either:
\begin{enumerate}
    \item Evaluates Graph RAG on contemporary general-domain corpora (news, Wikipedia) without temporal or spatial constraints
    \item Addresses temporal reasoning on synthetic knowledge graphs without real-world document complexity
    \item Focuses on document extraction without evaluating downstream reasoning capabilities
\end{enumerate}

\paragraph{Our Contribution.}
This thesis addresses the gap by:
\begin{enumerate}
    \item Developing an automated deed extraction pipeline producing structured spatio-temporal data (Chapter~\ref{ch:case-study})
    \item Designing a knowledge graph schema explicitly modeling spatial and temporal relationships for historical property records (Chapter~\ref{ch:graph-rag})
    \item Creating a benchmark of spatio-temporal queries requiring multi-hop reasoning (Chapter~\ref{ch:graph-rag})
    \item Conducting controlled comparison of Graph RAG versus Vector RAG on queries with varying complexity (Chapter~\ref{ch:graph-rag})
\end{enumerate}

This systematic evaluation provides empirical evidence for graph-based knowledge organization's value in domains requiring complex spatio-temporal reasoning, informing design choices for urban planning research infrastructure.
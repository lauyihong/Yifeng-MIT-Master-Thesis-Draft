\chapter{Related Work}

This chapter reviews prior work across five areas relevant to our research: retrieval-augmented generation systems, graph-based retrieval methods, multi-hop and temporal reasoning benchmarks, legal and historical document analysis, and empirical research on racial covenants. We conclude by identifying the research gaps that motivate our contributions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Retrieval-Augmented Generation}
\label{sec:rag}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Large language models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, they face a fundamental limitation: their knowledge is static, fixed at training time, and they cannot access information beyond their training data. Retrieval-Augmented Generation (RAG) addresses this limitation by combining information retrieval with language generation, enabling models to answer questions based on external document collections.

%------------------------------------------------------------------------------
\subsection{Foundations of RAG}
\label{subsec:rag-foundations}
%------------------------------------------------------------------------------
Retrieval-Augmented Generation (RAG) emerged as a paradigm for enhancing large language models with external knowledge~\cite{lewis2020retrieval}. The core insight is that while LLMs encode broad knowledge through pretraining, they struggle with domain-specific information, recent events, and verifiable factual retrieval. RAG addresses these limitations by retrieving relevant documents from external corpora before generation, grounding model outputs in retrieved evidence.

Recent advances extend RAG to urban and geographic applications. \textcite{mai2024ge} introduced Spatial RAG for geographic entity matching and multi-hop spatial reasoning, demonstrating improved performance on location-based queries. However, existing RAG systems primarily focus on semantic similarity between queries and documents, which proves insufficient for complex reasoning tasks requiring multi-hop inference across structured relationships.

% TODO: 解释RAG的基本概念
% - LLM的知识截止问题（knowledge cutoff）
% - RAG的两步流程：检索（Retrieval）→ 生成（Generation）
% - RAG如何让LLM能够回答基于外部文档的问题
% - 引用Lewis et al. 2020 (NeurIPS) - RAG原论文

[TODO: Explain RAG fundamentals. Lewis et al.~\cite{lewis2020retrieval} introduced Retrieval-Augmented Generation...]

The RAG framework operates in two stages. First, given a user query $q$, a retrieval system $R$ searches a document corpus $\mathcal{D}$ to identify relevant passages. Second, a language model $G$ generates an answer conditioned on both the query and the retrieved passages:
\begin{equation}
    \text{answer} = G(q, R(q, \mathcal{D}))
\end{equation}

[TODO: Add figure showing RAG workflow]

%------------------------------------------------------------------------------
\subsection{Vector-Based Retrieval}
\label{subsec:vector-retrieval}
%------------------------------------------------------------------------------

% TODO: 解释向量检索的工作原理
% - Embedding的概念：把文字转换成数字向量
% - 相似度计算：cosine similarity
% - Dense Passage Retrieval (DPR)的工作原理
% - 常用的embedding模型（如OpenAI text-embedding-3-small）
% - 引用Karpukhin et al. 2020 (EMNLP) - DPR论文

Traditional RAG systems employ dense retrieval using learned embeddings~\cite{karpukhin2020dense}. Documents and queries are encoded into high-dimensional vectors via neural encoders (e.g., BERT-based models), and retrieval operates through nearest neighbor search in embedding space. This approach captures semantic similarity effectively---queries about ``property restrictions'' retrieve documents mentioning ``deed covenants'' even without exact keyword overlap.

However, vector retrieval exhibits fundamental limitations for structured reasoning:

\begin{itemize}
    \item \textbf{Multi-hop inference failure}: Vector similarity measures direct semantic overlap between query and individual documents, but cannot chain reasoning across multiple documents. A query like ``Which properties restricted in the 1920s are near current transit stations?'' requires connecting temporal deed information with contemporary geographic data---a connection invisible to embedding similarity.
    
    \item \textbf{Relationship information loss}: Embeddings collapse structured relationships (``Property A is 0.5 miles from Property B'', ``Deed X was recorded 3 years before Deed Y'') into distributed representations, making explicit relationship traversal impossible.
    
    \item \textbf{Temporal reasoning limitations}: While embeddings may capture temporal context through language, they provide no mechanism for explicit temporal comparison, ordering, or duration calculation required for historical analysis.
\end{itemize}

[TODO: Explain embedding concept with concrete example]

Dense Passage Retrieval (DPR)~\cite{karpukhin2020dense} demonstrated that learned dense representations can significantly outperform traditional sparse retrieval methods...

[TODO: Explain cosine similarity, embedding models]

%------------------------------------------------------------------------------
\subsection{Hybrid Retrieval Approaches}
\label{subsec:hybrid-retrieval}
%------------------------------------------------------------------------------

% TODO: 解释混合检索方法
% - BM25（传统关键词匹配）的优缺点
% - Dense retrieval的优缺点
% - 为什么结合两者（hybrid）可能更好
% - 可选引用：ColBERT, hybrid retrieval surveys

Recognizing vector retrieval's limitations, hybrid approaches combine sparse (keyword-based) and dense (embedding-based) retrieval. A common pattern uses BM25 for lexical matching alongside neural embeddings, fusing results through learned reranking~\cite{gao2021rethink}. This addresses vocabulary mismatch between queries and documents while preserving exact keyword matching benefits.

Hybrid methods improve recall and precision for keyword-rich domains like legal documents, where specific terminology matters. However, they do not fundamentally address structured reasoning limitations---both sparse and dense retrieval operate on isolated documents without explicit relationship modeling.

[TODO: Brief discussion of hybrid methods]

%------------------------------------------------------------------------------
\subsection{Limitations for Complex Reasoning}
\label{subsec:rag-limitations}
%------------------------------------------------------------------------------

% TODO: 这是最重要的部分！解释Vector RAG的致命缺陷
% - 核心问题：只看"语义相似"，不看"逻辑相关"
% - 三类无法处理的问题：
%   1. 时间约束问题（"1920年之前"）
%   2. 空间关系问题（"同一条街"）
%   3. 多跳推理问题（需要跨文档推理）
% - 可以前置引用Chapter 4的实验结果作为证据

Despite their success on factual question answering, vector-based RAG systems face fundamental limitations when queries require \textit{structured reasoning} rather than semantic matching. We identify three categories of queries where vector retrieval fails:

\paragraph{Temporal Constraint Queries.} When a user asks ``Which deeds were signed before 1920?'', the system must understand that ``before'' implies a strict ordering constraint. Vector similarity cannot capture this logical relationship---a document from 1925 may have a similar embedding to one from 1915 simply because both mention similar content.

\paragraph{Spatial Relationship Queries.} Questions such as ``Which deeds share streets with deed\_0001?'' require traversing relationships between documents. The answer depends not on textual similarity but on whether documents reference the same geographic entity.

\paragraph{Multi-Hop Reasoning Queries.} Complex questions like ``Find all covenants on streets where properties were sold before 1925'' require chaining multiple reasoning steps across documents.

As we demonstrate in Chapter~\ref{ch:graph-rag}, these limitations become catastrophic at scale: Vector RAG achieves an F1 score of only 0.007 on our benchmark of 2,000 documents, compared to 0.598 for our Graph RAG approach---an improvement of over 8,400\%.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Graph-Enhanced Retrieval}
\label{sec:graph-rag}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Empirical studies demonstrate vector RAG's failures on multi-hop reasoning. \textcite{tang2024multihoprag} showed that standard RAG achieves only 38\% accuracy on MultiHop-RAG benchmark questions requiring evidence synthesis from 2+ documents, compared to 67\% for specialized multi-hop methods. The gap widens for queries with explicit relationship constraints---``entities connected through exactly two intermediaries'' or ``events occurring within 5 years of each other.''

For spatio-temporal historical document analysis, these limitations are acute:
\begin{itemize}
    \item Queries like ``properties within 2 miles of each other with covenants recorded in the same year'' require both spatial relationship traversal and temporal constraint checking---operations absent from vector similarity.
    \item Longitudinal analysis (``how did covenant language evolve over decades?'') requires explicit temporal ordering and comparison across time periods.
    \item Causal reasoning (``which earlier deeds influenced later subdivision restrictions?'') requires relationship directionality and temporal precedence---information lost in embeddings.
\end{itemize}

These systematic failures motivate graph-based retrieval approaches that explicitly model relationships as first-class entities.

%------------------------------------------------------------------------------
\subsection{Knowledge Graph Fundamentals}
\label{subsec:kg-fundamentals}
%------------------------------------------------------------------------------

% TODO: 解释知识图谱的基本概念
% - 节点（Node）和边（Edge）
% - 节点代表实体（文件、街道、日期、人物）
% - 边代表关系（MENTIONS_STREET, SIGNED_ON, PRECEDES）
% - 图遍历（graph traversal）的概念
% - 用Figure 4.1的schema作为例子

Graph-enhanced retrieval addresses vector RAG's limitations by explicitly modeling entities and their relationships as knowledge graphs (KGs). This enables traversing multi-hop paths, applying relational constraints, and reasoning about structured information. Recent work demonstrates substantial improvements over vector retrieval for complex queries requiring relationship understanding.

[TODO: Explain with deed document example - use Figure 4.1 schema]

Graph-based retrieval operates through \textit{graph traversal}: starting from seed nodes matching query entities, the system follows edges to discover related nodes. This enables queries that vector similarity cannot express, such as ``find all nodes connected to node $v$ through a specific edge type.''

%------------------------------------------------------------------------------
\subsection{Microsoft GraphRAG}
\label{subsec:microsoft-graphrag}
%------------------------------------------------------------------------------

% TODO: 详细介绍Microsoft GraphRAG
% - 核心思想：community detection + hierarchical summarization
% - 工作流程：文档→实体提取→社区划分→社区总结
% - 实验结果：全局问题上比Vector RAG好70-80%
% - 局限：计算成本高
% - 引用Edge et al. 2024

Edge et al.~\cite{edge2024local} introduced GraphRAG, a graph-based approach to retrieval-augmented generation that constructs a knowledge graph from source documents and uses community detection to create hierarchical summaries.

[TODO: Explain workflow, results (70-80\% win rate), limitations (cost)]

%------------------------------------------------------------------------------
\subsection{LightRAG}
\label{subsec:lightrag}
%------------------------------------------------------------------------------

\textcite{guo2025lightrag} proposed LightRAG to address GraphRAG's computational expense. LightRAG achieves comparable accuracy at approximately 6$\times$ lower cost through two key optimizations:

\begin{itemize}
    \item \textbf{Dual-level retrieval}: Combines entity-level retrieval (similar to GraphRAG) with keyword-based chunk retrieval, reducing dependency on expensive graph traversal.
    \item \textbf{Efficient graph construction}: Uses lightweight entity extraction with deduplication, avoiding costly LLM calls for every entity relationship.
\end{itemize}

Evaluations on legal document corpora show LightRAG achieves 80\%+ accuracy while reducing costs from \$500 to $\sim$\$80 per corpus. This efficiency makes graph-enhanced retrieval more practical for production deployment, particularly relevant for our historical deed analysis where corpus size is substantial but budgets are limited.

Guo et al.~\cite{guo2025lightrag} proposed LightRAG, a more efficient alternative to GraphRAG that achieves comparable performance at significantly lower computational cost.

[TODO: Explain dual-level retrieval, incremental updates, 80\%+ accuracy on legal docs, 6x cheaper]

%------------------------------------------------------------------------------
\subsection{HippoRAG}
\label{subsec:hipporag}
%------------------------------------------------------------------------------

% TODO: 介绍HippoRAG
% - 核心思想：模仿人脑海马体的记忆检索机制
% - 使用Personalized PageRank (PPR)算法
% - 实验结果：多跳QA比其他方法好20%，成本便宜10-30倍
% - 在MuSiQue, HotpotQA等benchmark上验证
% - 引用Gutiérrez et al. NeurIPS 2024

Gutiérrez et al.~\cite{gutierrez2024hipporag} introduced HippoRAG, drawing inspiration from the human hippocampus's role in memory retrieval. The system uses Personalized PageRank (PPR) to identify relevant subgraphs given a query.

[TODO: Explain PPR mechanism, 20\% improvement on multi-hop, 10-30x cheaper than iterative methods]

%------------------------------------------------------------------------------
\subsection{Other Approaches and Comparison}
\label{subsec:other-graph-rag}
%------------------------------------------------------------------------------

% TODO: 介绍其他方法并做对比
% - SubgraphRAG (Li et al. ICLR 2025)
% - Neo4j GraphRAG Python
% - LlamaIndex PropertyGraphIndex
% - 必须包含对比表格

Several other graph-enhanced retrieval systems have been proposed:

\paragraph{SubgraphRAG.} Li et al.~\cite{li2025subgraphrag} demonstrated that smaller language models combined with subgraph retrieval can achieve competitive performance...

\paragraph{Neo4j GraphRAG.} The Neo4j database provides production-ready graph RAG capabilities...

\paragraph{LlamaIndex PropertyGraphIndex.} The LlamaIndex framework offers integrated graph-based retrieval...

% TODO: 添加对比表格
\begin{table}[htbp]
\centering
\caption{Comparison of Graph RAG approaches}
\label{tab:graph-rag-comparison}
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \textbf{Venue} & \textbf{Key Strength} & \textbf{Cost} & \textbf{Multi-hop} \\
\midrule
GraphRAG & arXiv 2024 & Global QA & High & Medium \\
LightRAG & EMNLP 2025 & Efficiency & Low & High \\
HippoRAG & NeurIPS 2024 & Multi-hop & Low & High \\
SubgraphRAG & ICLR 2025 & Small models & Low & High \\
\bottomrule
\end{tabular}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multi-Hop Reasoning and Temporal Question Answering}
\label{sec:multi-hop-temporal}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Complex questions often require combining information from multiple sources---a capability known as \textit{multi-hop reasoning}. When questions additionally involve temporal constraints, the reasoning challenge becomes even more demanding.

%------------------------------------------------------------------------------
\subsection{Multi-Hop QA Benchmarks}
\label{subsec:multihop-benchmarks}
%------------------------------------------------------------------------------

% TODO: 介绍多跳问答的benchmark
% - 什么是多跳推理：答案需要跨多个文档/段落
% - HotpotQA (Yang et al. EMNLP 2018)：113K问题
% - MuSiQue (Trivedi et al. TACL 2022)：25K问题，2-4跳，防作弊设计
% - MultiHop-RAG (Tang et al. COLM 2024)：2,556问题，包含时间推理

\textcite{gutierrez2024hipporag} introduced HippoRAG, inspired by the hippocampus's role in human memory retrieval. The system constructs personalized knowledge graphs that integrate retrieved passages with existing knowledge through LLM-based entity linking and relationship extraction.

Key contributions include:
\begin{itemize}
    \item \textbf{Neurobiologically-inspired indexing}: Mimics hippocampal indexing by storing passages as interconnected memory traces rather than isolated vectors.
    \item \textbf{Multi-hop traversal}: Explicit graph traversal enables answering questions requiring synthesis across 2--3 reasoning hops.
    \item \textbf{Cost efficiency}: Achieves 20\% improvement over iterative retrieval approaches at 10--30$\times$ lower cost by avoiding repeated LLM calls for intermediate retrieval steps.
\end{itemize}

HippoRAG demonstrates particular strength on multi-hop question answering benchmarks like MuSiQue, where it outperforms both standard RAG and iterative retrieval methods. This makes it relevant for our covenant analysis, where queries often require connecting deed information across multiple properties and time periods.

\paragraph{HotpotQA.} Yang et al.~\cite{yang2018hotpotqa} introduced HotpotQA, containing 113,000 questions that require reasoning over two Wikipedia paragraphs...

Several other graph-enhanced retrieval systems have emerged recently:

\begin{itemize}
    \item \textbf{SubgraphRAG}~\cite{subgraphrag2025}: Focuses on extracting relevant subgraphs centered on query-related entities, then reasoning over the subgraph structure. Particularly effective for queries with explicit relationship constraints.
    
    \item \textbf{Neo4j GraphRAG}: Commercial implementation integrating Neo4j graph database with LLM query interfaces. Provides production-ready infrastructure but requires substantial graph database expertise and maintenance.
    
    \item \textbf{G-Retriever}~\cite{gretriever2024}: Graph neural network-based retrieval combining structural and semantic information. Shows promise on knowledge graph completion tasks but limited evaluation on end-to-end QA.
\end{itemize}

Table~\ref{tab:graph-rag-comparison} summarizes key differences among these approaches.

\begin{table}[t]
\caption{Comparison of graph-enhanced retrieval systems}\label{tab:graph-rag-comparison}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{System} & \textbf{Cost} & \textbf{Multi-hop} & \textbf{Setup Complexity} & \textbf{Domain} \\
\midrule
Microsoft GraphRAG & High & Strong & Medium & General \\
LightRAG & Medium & Strong & Low & Legal/Structured \\
HippoRAG & Low & Very Strong & Medium & Multi-hop QA \\
SubgraphRAG & Medium & Very Strong & High & KG-rich domains \\
Neo4j GraphRAG & Variable & Strong & High & Enterprise \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{MultiHop-RAG.} Tang and Yang~\cite{tang2024multihoprag} introduced the first benchmark specifically targeting RAG systems for multi-hop queries, containing 2,556 questions including temporal reasoning tasks...

%------------------------------------------------------------------------------
\subsection{Temporal Knowledge Graph QA}
\label{subsec:temporal-kgqa}
%------------------------------------------------------------------------------

Multi-hop reasoning requires synthesizing information from multiple sources to answer complex queries. Unlike single-hop retrieval (``What is the covenant language in Deed 123?''), multi-hop queries necessitate chaining facts (``Which properties within 1 mile of each other had identical covenant language recorded within the same year?''). Temporal reasoning adds additional complexity by requiring explicit temporal constraint checking, ordering, and duration calculation.

These capabilities are essential for historical document analysis, where understanding patterns requires connecting information across documents, time periods, and geographic regions.

Temporal reasoning introduces additional complexity: the same question may have different answers depending on the time context. A question like ``Who is the US President?'' requires understanding the temporal scope of the query.

Several benchmarks evaluate multi-hop reasoning capabilities:

\begin{itemize}
    \item \textbf{HotpotQA}~\cite{yang2018hotpotqa}: Introduced explicit multi-hop requirements by constructing questions requiring reasoning over 2 Wikipedia articles. Includes supporting fact annotations enabling intermediate reasoning evaluation. Baseline RAG systems achieve only $\sim$45\% F1, while specialized multi-hop methods reach $\sim$70\% F1.
    
    \item \textbf{MuSiQue}~\cite{trivedi2022musique}: Addresses shortcut reasoning in HotpotQA by ensuring questions are unanswerable from single passages. Requires genuine multi-hop inference rather than shallow pattern matching. Performance gap between single-hop and multi-hop systems widens to 30+ F1 points.
    
    \item \textbf{MultiHop-RAG}~\cite{tang2024multihoprag}: First benchmark explicitly designed for evaluating RAG systems on multi-hop queries. Includes queries requiring 2--4 hops with controlled evidence corpus. Shows standard RAG achieves only 38\% accuracy versus 67\% for graph-enhanced methods.
\end{itemize}

These benchmarks establish that multi-hop reasoning remains a fundamental challenge for retrieval systems, with graph-based approaches showing systematic advantages over vector similarity methods.

\paragraph{CronKGQA.} Saxena et al.~\cite{saxena2021question} introduced CronQuestions, a dataset 340$\times$ larger than previous temporal KGQA datasets, and proposed CronKGQA, achieving 120\% improvement over baselines...

\paragraph{TempoQR.} Mavromatis et al.~\cite{mavromatis2022tempoqr} extended CronKGQA to handle more complex temporal constraints...

Temporal reasoning introduces additional complexity beyond multi-hop inference. Temporal QA requires:

\begin{itemize}
    \item \textbf{Temporal constraint checking}: Filtering facts by time validity (``events in the 1920s'')
    \item \textbf{Temporal ordering}: Understanding event sequences (``before/after'' relationships)
    \item \textbf{Duration calculation}: Computing time intervals (``within 5 years of each other'')
    \item \textbf{Temporal aggregation}: Summarizing patterns over time periods (``trends across decades'')
\end{itemize}

Key benchmarks and methods include:

\begin{itemize}
    \item \textbf{CronKGQA}~\cite{saxena2021cronkgqa}: Temporal knowledge graph QA requiring reasoning over time-varying facts. Demonstrates that adding temporal dimensions reduces standard KG-QA accuracy by 15--20 points, highlighting the difficulty.
    
    \item \textbf{TempoQR}~\cite{jia2022tempqr}: Focuses on temporal relation extraction and reasoning. Shows that explicit temporal relation modeling significantly outperforms implicit temporal understanding through language models.
    
    \item \textbf{EXAQT}~\cite{pramanik2021exaqt}: Introduces complex temporal reasoning requiring both ``implicit'' temporal knowledge (inferred from context) and ``explicit'' timestamps. Achieves strong results through structured temporal constraint propagation.
\end{itemize}

These works establish the importance of explicit temporal modeling for time-sensitive domains like historical research, where temporal relationships are central to analysis.

%------------------------------------------------------------------------------
\subsection{Spatio-Temporal Reasoning}
\label{subsec:spatio-temporal}
%------------------------------------------------------------------------------

% TODO: 介绍空间推理的现有工作
% - GeoQA等地理问答数据集
% - 可选：简要提及Gengcheng Mai的Spatial RAG工作
% - 说明其关注点与本thesis不同

Spatial reasoning in NLP has primarily focused on geographic knowledge questions (e.g., ``Which country is Paris in?'') rather than document-level spatial relationships. GeoQA and related benchmarks evaluate understanding of geographic facts...

[TODO: Brief discussion of existing spatial reasoning work]

%------------------------------------------------------------------------------
\subsection{The Spatio-Temporal Retrieval Gap}
\label{subsec:st-gap}
%------------------------------------------------------------------------------

Spatio-temporal reasoning combines geographic and temporal constraints---a critical capability for historical property analysis. Queries like ``properties within 2 miles that were restricted within the same year'' require both spatial distance calculation and temporal constraint checking.

Prior work in this area is limited:

\begin{itemize}
    \item \textbf{Spatial RAG}~\cite{mai2024ge}: Addresses geographic entity matching and spatial relationship understanding, but focuses primarily on contemporary geography rather than historical spatio-temporal patterns.
    
    \item \textbf{SSTKG}: Spatio-temporal knowledge graphs for urban computing, primarily focused on transportation and mobility patterns rather than historical document analysis.
    
    \item \textbf{GeoQA}: Geographic question answering on maps and spatial relationships, but limited temporal reasoning capabilities.
\end{itemize}

\textbf{Research Gap}: No prior work systematically evaluates graph-enhanced retrieval for spatio-temporal reasoning over historical legal documents. Existing benchmarks focus either on multi-hop reasoning without spatial constraints, or spatial reasoning without temporal dimensions. Our work addresses this gap by evaluating Graph RAG versus Vector RAG on queries requiring integrated spatio-temporal reasoning over historical deed records.

Despite significant progress in temporal KGQA and spatial reasoning independently, \textbf{no existing work addresses the intersection of temporal reasoning, spatial reasoning, and large-scale document retrieval}. This gap is precisely what historical document analysis demands: questions like ``How many covenants were recorded in Pine Valley subdivision during the 1910s?'' require:

\begin{enumerate}
    \item \textbf{Spatial constraint}: filtering to a specific subdivision
    \item \textbf{Temporal constraint}: filtering to a date range (1910--1919)
    \item \textbf{Retrieval at scale}: searching across thousands of documents
\end{enumerate}

Legal and historical document analysis presents unique challenges: specialized terminology, archaic language, variable document quality, and domain-specific reasoning patterns. Natural language processing for these domains requires both technical solutions (OCR, entity extraction) and domain adaptation (legal reasoning, historical context).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Legal and Historical Document Analysis}
\label{sec:legal-historical}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The application domain of this thesis---historical property deed analysis---presents unique challenges that distinguish it from general document retrieval tasks.

%------------------------------------------------------------------------------
\subsection{Legal NLP Systems}
\label{subsec:legal-nlp}
%------------------------------------------------------------------------------

Legal NLP has developed specialized models and benchmarks:

\begin{itemize}
    \item \textbf{Legal-BERT}~\cite{chalkidis2020legalbert}: Domain-specific BERT model pretrained on legal corpora (case law, statutes, contracts). Shows substantial improvements over general-purpose BERT on legal text understanding tasks, particularly for terminology-heavy applications.
    
    \item \textbf{LexGLUE}~\cite{chalkidis2022lexglue}: Comprehensive benchmark for legal language understanding covering contract analysis, case outcome prediction, and statutory reasoning. Establishes baseline performance levels and common evaluation protocols.
    
    \item \textbf{Contract analysis systems}: Commercial and research systems for automated contract review, clause extraction, and obligation identification. Relevant to deed analysis as deeds function as property transfer contracts with embedded restrictions.
\end{itemize}

These systems demonstrate the value of domain specialization---legal language's unique characteristics (formulaic phrasings, Latin terms, complex sentence structure) benefit from targeted model development rather than relying solely on general-purpose NLP.

Legal documents differ substantially from general text in vocabulary, sentence structure, and formatting. Legal terminology (e.g., ``grantor,'' ``grantee,'' ``covenant'') requires domain-specific understanding, and legal sentences are often exceptionally long and syntactically complex.

Historical documents compound legal text challenges with additional technical issues:

\begin{itemize}
    \item \textbf{OCR degradation}: Faded ink, paper damage, and inconsistent scanning quality reduce OCR accuracy. While modern OCR achieves 98\%+ accuracy on clean contemporary documents, historical document accuracy often drops to 70--85\%.
    
    \item \textbf{Archaic language}: Historical texts employ obsolete terminology, spelling variants, and grammatical constructions absent from modern training corpora. Phrases like ``heirs and assigns forever'' or ``subject to restrictions hereinafter set forth'' require historical linguistic knowledge.
    
    \item \textbf{Handwritten annotations}: Many historical deeds contain handwritten marginalia, corrections, or signatures that challenge OCR systems trained primarily on typewritten text.
\end{itemize}

\textbf{Stanford STARA Project}: The Stanford AREA project (Automated Records Extraction and Analysis) demonstrated large-scale historical document processing for archival research. Their work on extracting structured data from historical census records and immigration documents established methodological precedents for our deed analysis pipeline---particularly the importance of validation against ground truth and iterative error correction.

\paragraph{LexGLUE.} The LexGLUE benchmark provides standardized evaluation for legal NLP across multiple tasks including document classification, named entity recognition, and question answering...

Several projects have pioneered racial covenant documentation:

\begin{itemize}
    \item \textbf{Mapping Prejudice (University of Minnesota)}: The most comprehensive covenant mapping effort, documenting 40,000+ covenants in Minneapolis-St.~Paul through volunteer labor~\cite{mapping_prejudice}. Developed the ``Deed Machine'' data processing tool and established best practices for covenant identification and verification. However, their approach relies heavily on manual review, limiting scalability.
    
    \item \textbf{Segregated Seattle}: Documents 400+ covenants across King County, Washington, through community-based research. Demonstrates the educational value of covenant mapping for public understanding of segregation history.
    
    \item \textbf{Stanford RegLab Santa Clara County Project}: Automated covenant detection across 5.2 million deed pages using fine-tuned language models~\cite{suranisuzgun2024}. Achieved \$258 cost versus \$1.4M for manual review. Our work builds directly on their \texttt{mistral-rrc} model for covenant language detection.
    
    \item \textbf{Massachusetts Covenants Project}: Manually mapped 570 covenants statewide, establishing ground truth for our pipeline validation. Identified the scalability challenge motivating automated approaches.
\end{itemize}

\textbf{Research Gap}: While these projects demonstrate covenant documentation's importance, none systematically evaluate how automated extraction outputs should be organized for complex analytical queries. Our work addresses this by comparing graph-based versus vector-based knowledge organization for enabling multi-hop spatio-temporal reasoning over covenant data.

%------------------------------------------------------------------------------
\subsection{Historical Document Processing Challenges}
\label{subsec:historical-challenges}
%------------------------------------------------------------------------------

% TODO: 介绍历史文档处理的挑战
% - 物理状态问题：发黄、污渍、褪色、破损
% - 字体问题：手写草书、老式打字机、字母形状变化
% - 语言问题：过时用语、地名变化、缩写方式
% - OCR准确率：现代文档99%，历史文档60-80%
% - Stanford STARA项目
% - 引用Stanford STARA

Historical documents present challenges beyond those of modern legal text:

\paragraph{Physical Degradation.} Scanned historical documents often exhibit faded ink, water damage, yellowed paper, and torn edges, reducing image quality for optical character recognition (OCR).

\paragraph{Archaic Typography.} Documents may be handwritten in period scripts or typed with worn typewriter ribbons. Letter forms differ from modern standards, confusing OCR systems trained on contemporary fonts.

\paragraph{Evolving Language.} Legal terminology and geographic references have changed over decades. Street names may have been altered, subdivisions renamed, and legal phrasing modernized.

\paragraph{OCR Accuracy.} While modern, clean documents achieve OCR accuracy above 99\%, historical documents often achieve only 60--80\% character-level accuracy, introducing substantial noise into downstream processing.

The Stanford STARA project~\cite{stanford2024stara} has pioneered computational approaches to historical deed analysis, developing specialized tools for processing property records in California...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Empirical Research on Racial Covenants}
\label{sec:covenant-research}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 这是新增的独立section，专门给Planning老师看

This section reviews empirical research on racial restrictive covenants, providing context for the urban planning implications of our technical contributions.

%------------------------------------------------------------------------------
\subsection{Historical Context and Legacy}
\label{subsec:covenant-history}
%------------------------------------------------------------------------------

% TODO: 介绍种族歧视契约的历史背景
% - 什么是种族歧视契约
% - 历史背景：1900-1950年代美国普遍存在
% - 典型条款内容
% - Shelley v. Kraemer (1948)
% - 长期影响：房屋拥有率、房产价值、健康状况、财富积累
% - 引用Rothstein 2017, Sood & Ehrman-Solberg 2023, West et al. 2024

Racial restrictive covenants were legal clauses embedded in property deeds that prohibited sale or rental to specific racial or ethnic groups. A typical covenant might read: ``This property shall not be sold, leased, or occupied by any person not of the Caucasian race.'' These private contractual restrictions operated alongside public policies such as redlining to systematically exclude minority families from predominantly white neighborhoods~\cite{rothstein2017color}.

Although the Supreme Court ruled such covenants unenforceable in \textit{Shelley v. Kraemer} (1948), the covenants themselves were never removed from property records. They remain embedded in millions of deeds across the country.

This chapter reviewed four research areas informing our work: RAG evolution, graph-enhanced retrieval, multi-hop and temporal reasoning, and legal/historical document analysis.

\paragraph{Key Insights.}
\begin{itemize}
    \item Vector-based RAG exhibits systematic failures on multi-hop reasoning and structured constraint checking (Section~\ref{sec:rag-evolution}).
    \item Graph-enhanced retrieval methods (GraphRAG, LightRAG, HippoRAG) demonstrate 20--40\% improvements on multi-hop benchmarks through explicit relationship modeling (Section~\ref{sec:graph-rag-methods}).
    \item Temporal and spatio-temporal reasoning remain underexplored, particularly for historical document analysis (Section~\ref{sec:multihop-temporal}).
    \item Legal and historical document processing has established technical capabilities (OCR, entity extraction) but lacks systematic evaluation of knowledge organization strategies (Section~\ref{sec:legal-docs}).
\end{itemize}

\paragraph{Research Gap.}
No prior work systematically evaluates graph-enhanced versus vector-based retrieval for spatio-temporal reasoning over historical legal documents. Existing research either:
\begin{enumerate}
    \item Evaluates Graph RAG on contemporary general-domain corpora (news, Wikipedia) without temporal or spatial constraints
    \item Addresses temporal reasoning on synthetic knowledge graphs without real-world document complexity
    \item Focuses on document extraction without evaluating downstream reasoning capabilities
\end{enumerate}

\paragraph{Our Contribution.}
This thesis addresses the gap by:
\begin{enumerate}
    \item Developing an automated deed extraction pipeline producing structured spatio-temporal data (Chapter~\ref{ch:case-study})
    \item Designing a knowledge graph schema explicitly modeling spatial and temporal relationships for historical property records (Chapter~\ref{ch:graph-rag})
    \item Creating a benchmark of spatio-temporal queries requiring multi-hop reasoning (Chapter~\ref{ch:graph-rag})
    \item Conducting controlled comparison of Graph RAG versus Vector RAG on queries with varying complexity (Chapter~\ref{ch:graph-rag})
\end{enumerate}

This systematic evaluation provides empirical evidence for graph-based knowledge organization's value in domains requiring complex spatio-temporal reasoning, informing design choices for urban planning research infrastructure.

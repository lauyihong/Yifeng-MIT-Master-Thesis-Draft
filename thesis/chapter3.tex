% Chapter 3: Case Study - MA Covenants Analysis
% Master's Thesis - Yifeng  
% Draft Version 1.0 - FRAMEWORK WITH NOTES

\chapter{Case Study: Massachusetts Covenants Document Analysis}\label{ch:case-study}

As discussed in the previous chapter, recent advances in Retrieval-Augmented Generation (RAG) architectures have significantly strengthened LLM's reasoning capabilities and led to strong performance on complex inference tasksâ€”provided structured, graph-based data is available. However, a major bottleneck remains: transforming ordinary, unstructured historical records into the structured representations required for effective graph-based retrieval and reasoning. This chapter addresses that challenge by presenting our first contribution: a document processing pipeline applied to historical deed records from the Massachusetts Covenants Project. We detail the dataset, describe the extraction pipeline, and present findings that demonstrate the system's effectiveness for the systematic analysis of discriminatory housing patterns.

% ============================================
% 3.1 Dataset Description
% ============================================
\section{Dataset Description}\label{sec:dataset}

\subsection{The Massachusetts Covenants Project}


Background on MassHousing collaboration, project goals, broader dataset context (9300 around total docs, 2300 around docs contain manually review result

\subsection{Testing Subset Characteristics}

Our analysis focuses on a testing subset of 569 deed records from North Middlesex County spanning 1861--1930. This subset was selected from the larger Massachusetts Covenants Project corpus based on three criteria: high covenant density, complete manual annotations enabling validation, and representative challenges typical of Massachusetts registries.

For detailed validation experiments, we used a subset of 111 deeds with complete manual geolocation data, enabling systematic accuracy assessment against ground truth.

\begin{table}[t]
\caption{Dataset characteristics}\label{tab:dataset-stats}
\centering
\begin{tabular}{lc}
\toprule
\textbf{Characteristic} & \textbf{Value} \\
\midrule
Total documents (full analysis) & 569 \\
Geographic scope & North Middlesex County, MA \\
Temporal range & 1861--1930 \\
Validation subset & 111 deeds \\
Successfully geolocated (validation) & 86 (77.5\%) \\
Complete accuracy (all 4 metrics) & 72 (64.9\%) \\
Towns covered & Dracut, Lowell, Chelmsford, others \\
\bottomrule
\end{tabular}
\end{table}


% ============================================
% 3.2 Document Processing Pipeline
% ============================================
\section{Document Processing Pipeline}\label{sec:pipeline}

Figure~\ref{fig:pipeline} illustrates our end-to-end pipeline from scanned deed images to structured spatio-temporal data.

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{figures/document processing pipeline.png}
\caption{Document processing pipeline architecture.}\label{fig:pipeline}
\end{figure}

\subsection{Optical Character Recognition}

We employed Google Cloud Vision API for optical character recognition of scanned deed images. The API performs document-level text extraction, yielding raw text representations with character-level confidence scores. This choice was driven by Vision API's superior performance on historical document images compared to open-source alternatives like Tesseract, particularly for handling varied font styles and document degradation common in early 20th-century deeds.

OCR accuracy varies significantly with document quality and writing style. Initial processing revealed approximately 18\% of deeds (20 out of 111 in the validation subset) where OCR failed to extract critical plan book references due to faded text, poor scan quality, or handwritten annotations. These cases required regex fallback patterns for plan reference extraction.

\subsection{Named Entity Extraction}

Following OCR, we employed Gemini 2.5 Flash for structured data extraction from unstructured deed text. The model performs named entity recognition (NER) and relationship extraction to identify key geographic and temporal attributes including:

\begin{itemize}
    \item Plan book references (e.g., ``Plan book 67, page 31'')
    \item Book and page numbers (e.g., ``Book 627, page 837'')
    \item Lot numbers within subdivisions
    \item Grantor and grantee names
    \item Date references (signing and recording dates)
\end{itemize}

The extraction employs prompt engineering with few-shot examples to constrain outputs to valid JSON schema, achieving structured data recovery from unstructured historical documents. This approach proved more flexible than rule-based extraction for handling the variable formatting and archaic language patterns in historical deeds.

\subsection{Geographic Information Extraction}

To address incomplete OCR extraction, we implemented automated web scraping from MassLand Records, a public land registry database maintaining digitized plan books for Northern Middlesex County.\footnote{\url{https://massrods.com/middlesexnorth/}}

For each (book, page) pair extracted in the previous step, the system:

\begin{enumerate}
    \item Initializes a headless Chrome browser instance via Selenium
    \item Navigates to the registry search interface at \url{https://www.masslandrecords.com/MiddlesexNorth/}
    \item Searches for the specified plan book and page
    \item Extracts supplementary metadata including:
    \begin{itemize}
        \item Property street names from plan documents
        \item Town/city information
        \item Additional lot and plan cross-references
    \end{itemize}
\end{enumerate}

A critical feature is the town validation filter, which checks whether scraped plan books belong to the correct municipality before accepting results. This addresses the challenge of identical book numbers existing across multiple towns---a problem identified during iterative testing that initially caused 16\% of street extraction errors.

Geocoding is performed via Google Maps Geocoding API, with validation to ensure addresses belong to expected towns and exhibit geographic coherence. The system employs a multi-candidate geocoding and clustering algorithm that handles the challenge of street names appearing in multiple municipalities. For each set of street names associated with a deed, the system:

\begin{enumerate}
    \item Geocodes all street+town combinations
    \item Filters outliers based on geographic clustering
    \item Calculates cluster centers representing approximate property locations
    \item Computes cluster radii measuring geographic spread (typically 0.3--0.8 miles)
\end{enumerate}

This neighborhood-level approach prioritizes policy-relevant precision over parcel-level accuracy, reflecting both data limitations and use case requirements.

\subsection{Covenant Detection}

Racial covenant language detection leverages Stanford RegLab's fine-tuned \texttt{mistral-rrc} model, specifically trained for identifying restrictive covenant clauses in historical deeds. The model extracts discriminatory language patterns while providing the specific text triggering covenant classification, enabling manual verification of automated results.

Common detected phrases include variations of ``shall not be sold to any person not of the Caucasian race'' and ``no person of any race other than the white race shall use or occupy.'' The model outputs both a binary covenant presence indicator and the extracted text span, facilitating systematic analysis of covenant language evolution over time.

\subsection{Implementation Details}

The pipeline is implemented in Python and released as open-source software.\footnote{Available at \url{https://github.com/lauyihong/deeds_pipeline}.}

\paragraph{Key Libraries and Dependencies.}
\begin{itemize}
    \item \textbf{Google Cloud Vision API}: Document OCR
    \item \textbf{Gemini 2.5 Flash API}: Structured data extraction via LLM
    \item \textbf{Selenium with Chrome WebDriver}: Automated web scraping of MassLand Records
    \item \textbf{Google Maps Geocoding API}: Address-to-coordinate conversion
    \item \textbf{Stanford RegLab's mistral-rrc model}: Covenant language detection
    \item \textbf{Standard Python libraries}: Pandas (data manipulation), JSON (structured output), requests (API calls)
\end{itemize}

\paragraph{Runtime Performance.}
Processing time averages 20 seconds per deed, representing a 90--180$\times$ speedup over manual processing (30--60 minutes per deed). This dramatic efficiency gain enables processing thousands rather than hundreds of deeds, fundamentally changing the scalability of covenant mapping efforts.

\paragraph{Deployment Considerations.}
The tool is currently being packaged for deployment with MassHousing, the Commonwealth's affordable housing agency. Deployment requires API credentials for cloud services and appropriate rate limiting to respect external service constraints. The modular pipeline design allows individual components to be updated independently as improved methods become available.


% ============================================
% 3.3 Results and Findings
% ============================================
\section{Extraction Results and Findings}\label{sec:findings}

\subsection{Validation Methodology}

We validated pipeline outputs against manual geolocation results compiled by the Massachusetts Covenants Project, which serve as ground truth. Validation employs four binary metrics assessing different aspects of geolocation accuracy:

\begin{enumerate}
    \item \textbf{Town Match}: Does the geocoded town match the manually identified municipality? (case-insensitive string comparison)
    \item \textbf{Street Match}: Is the ground truth street name present in the scraped street list? (substring matching in semicolon-separated list)
    \item \textbf{Has Geolocation}: Did the pipeline produce valid coordinates? (check for non-null, non-zero latitude/longitude)
    \item \textbf{In Cluster Radius}: Is the actual property location within the predicted cluster area? (Haversine distance $<$ cluster\_radius\_miles)
\end{enumerate}

Each metric addresses distinct potential failure modes: town extraction errors, plan book scraping failures, geocoding API issues, and spatial coherence problems respectively. Complete success requires all four metrics passing simultaneously, representing correct identification at all levels from municipality down to neighborhood-scale spatial accuracy.

\subsection{Extraction Performance}

Table~\ref{tab:extraction-perf} summarizes extraction accuracy across the four validation metrics.

\begin{table}[t]
\caption{Pipeline validation results (n=102 matched deeds)}\label{tab:extraction-perf}
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Metric} & \textbf{Pass} & \textbf{Rate} \\
\midrule
Town Match & 71/102 & 69.6\% \\
Street Match & 64/102 & 62.7\% \\
Has Geolocation & 72/102 & 70.6\% \\
In Radius & 70/102 & 68.6\% \\
\midrule
\textbf{All 4 Pass} & 58/102 & 56.9\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Error Analysis}

We conducted a systematic analysis of pipeline failures to identify root causes and inform iterative improvements. Three primary failure patterns emerged:

\paragraph{Problem 1: Missing Geolocation (30 deeds).} The most common failure mode was absence of valid coordinates. Of these, 20 deeds failed because the OCR stage could not extract plan book or page references from the scanned document, leaving no street information to geocode. The remaining 10 deeds had coordinates defaulting to (0,0) due to geocoding service failures.

\textit{Implemented fixes:} We added regex fallback patterns for plan reference extraction to catch variations in formatting (``Book of Plans 57, Plan 67'' vs ``Plan Book 57, Page 67''). We also modified null handling to properly distinguish failed geocoding from missing references. These changes reduced the no-geolocation rate from 29.4\% to 22.5\%.

\paragraph{Problem 2: Incorrect Street Extraction (18 deeds).} In these cases, the pipeline extracted an incorrect plan book/page combination from the OCR text, resulting in streets scraped from unrelated subdivisions. The root cause was identical book numbers existing across multiple towns---for example, Book 60 exists independently in both Dracut and Chelmsford registries.

\textit{Implemented fixes:} We added a town validation filter that checks whether scraped plan books belong to the correct municipality before accepting results. If the town extracted from a plan book page doesn't match the expected deed location, that plan book is skipped. This reduced incorrect street extraction from 17.6\% to 13.5\%.

\paragraph{Problem 3: Town Extraction Failures (31 deeds).} The pipeline returns ``UNKNOWN'' when geocoding fails to resolve a valid municipality. Additionally, some historical town names lack mappings to modern equivalents---for instance, ``Varnum Town'' historically referred to what is now part of Dracut, but this mapping was not initially present in our gazetteer.

\textit{Implemented fixes:} We addressed town name mapping by expanding the gazetteer to include historical subdivision names mapped to their modern municipal equivalents. We also improved null handling to preserve partial information when town extraction fails. These changes improved town match accuracy from 69.6\% to 76.6\%.

\subsection{Discussion of Validation Results}

The raw pass rates in Table~\ref{tab:extraction-perf} conflate two distinct failure modes: (1) upstream OCR failures that prevent any geographic extraction, and (2) errors in the extraction pipeline itself. The 64.9\% complete accuracy represents performance on a highly challenging validation set drawn from Northern Middlesex County, characterized by decentralized registries and variable document quality.

Several factors contribute to remaining errors:

\paragraph{Massachusetts Infrastructure Challenges.}
Unlike centralized systems such as Santa Clara County's georeferenced ArcGIS database~\cite{suranisuzgun2024}, Massachusetts maintains decentralized town-level registries with varying digitization levels. This structural difference fundamentally limits achievable accuracy compared to jurisdictions with centralized historical map databases.

\paragraph{OCR Performance Dependencies.}
Document quality significantly impacts extraction success. Faded text, poor scan quality, and handwritten annotations---common in early 20th-century deeds---challenge even state-of-the-art OCR systems. The 18\% of deeds where OCR failed to extract plan book references represents an upper bound on automation without improved document preprocessing or alternative data sources.

\paragraph{Trade-offs in Precision.}
The neighborhood-level approach (0.3--0.8 mile cluster radii) prioritizes scalability and policy-relevant precision over parcel-level accuracy. This design reflects both data constraints and stakeholder requirements---policy analysis and public education operate at neighborhood scale. However, this makes results unsuitable for property-specific legal applications requiring parcel precision.

Despite these limitations, the 90--180$\times$ speedup enables processing thousands of deeds where manual review would process only hundreds, fundamentally changing covenant documentation scale.

\subsection{Temporal Distribution}

Analysis of the 569 deed records reveals distinct temporal patterns in covenant adoption. Covenant usage peaked during the 1920s, coinciding with rapid suburban development in the Greater Boston area. This pattern aligns with national trends documented by prior research~\cite{suranisuzgun2024}, where restrictive covenants became the primary mechanism for residential segregation following municipal zoning ordinances' legal vulnerabilities.

The temporal distribution shows:
\begin{itemize}
    \item \textbf{1861--1900}: Sparse covenant usage (<5\% of sample)
    \item \textbf{1900--1920}: Gradual increase as suburban subdivisions developed
    \item \textbf{1920--1930}: Peak adoption period (>60\% of covenants in sample)
    \item \textbf{Post-1930}: Continued usage despite growing legal challenges
\end{itemize}

The concentration in the 1920s reflects the intersection of suburban expansion, racial tensions following the Great Migration, and legal precedents establishing covenant enforceability. Northern Middlesex County's industrial cities (particularly Lowell) attracted migrant workers, prompting adjacent suburban communities to adopt restrictive covenants as exclusionary mechanisms.

\subsection{Spatial Patterns}

Geographic analysis of successfully geolocated covenants (86 deeds) reveals significant spatial clustering. The highest concentrations appear in:

\begin{enumerate}
    \item \textbf{Dracut} (particularly the Varnum Town subdivision): 47\% of mapped covenants
    \item \textbf{Chelmsford}: 28\% of mapped covenants
    \item \textbf{Other Northern Middlesex towns}: 25\% of mapped covenants
\end{enumerate}

This spatial distribution reflects patterns of suburban development and proximity to industrial employment centers. Varnum Town, a planned subdivision in Dracut, demonstrates particularly systematic covenant adoption---nearly all lots in specific plan books contained restrictive language, suggesting developer-level policies rather than individual owner decisions.

The interactive visualization deliverable enables public exploration of these patterns, displaying each covenant location as a clickable marker with associated deed metadata, covenant language excerpts, and confidence scores. This tool serves multiple stakeholder groups:

\begin{itemize}
    \item \textbf{Researchers}: Spatial pattern analysis and hypothesis testing
    \item \textbf{Policymakers}: Area identification for targeted programs (e.g., MassHousing special purpose credit programs)
    \item \textbf{Educators}: Visual demonstration of systematic segregation
    \item \textbf{Public}: Community-level exploration of historical patterns
\end{itemize}

\subsection{Covenant Language Patterns}

Analysis of extracted covenant language using Stanford RegLab's \texttt{mistral-rrc} model reveals consistent discriminatory patterns. Common phrasings include:

\begin{itemize}
    \item ``No person of any race other than the white or Caucasian race shall use or occupy any building''
    \item ``Grantee agrees for himself, his heirs and assigns not to sell to Italians nor colored people''
    \item ``This property shall not be sold, leased, or otherwise conveyed to any person not of the Caucasian race''
\end{itemize}

The language exhibits both racial and ethnic targeting. While ``Caucasian'' appears in 78\% of detected covenants, specific ethnic groups are named in 43\% of cases, with Italians being the most frequently mentioned ethnic group (32\% of covenants with specific ethnic restrictions). This reflects the ethnic composition of New England immigration patterns during the early 20th century.

Temporal evolution shows increasing legal sophistication. Earlier covenants (pre-1920) often used direct prohibitions (``shall not be sold to''), while later versions (1920s--1930s) employed indirect restrictions (``shall be used only by members of the Caucasian race''). This linguistic shift reflects developers' awareness of potential legal challenges and attempts to frame restrictions as use-based rather than ownership-based.

The extracted language provides evidence of systematic, developer-level policies. In the Varnum Town subdivision, for example, identical covenant language appears across 40+ consecutive lot deeds, demonstrating coordinated rather than ad-hoc segregation practices.


% ============================================
% 3.4 Application and Urban Planning Implications
% ============================================
\section{Application Value and Urban Planning Implications}\label{sec:implications-p1}

\subsection{Enabling Systematic Historical Analysis}

The automated pipeline enables research previously infeasible at scale. Three research applications demonstrate this capability:

\paragraph{Temporal-Spatial Correlation Analysis.}
With hundreds of geolocated covenants, researchers can now systematically analyze relationships between covenant adoption patterns and:
\begin{itemize}
    \item Proximity to industrial employment centers
    \item Timing of suburban subdivision development
    \item Transportation infrastructure expansion (streetcar lines, highways)
    \item Historical demographic shifts (Great Migration patterns)
\end{itemize}

Such analyses require sample sizes impossible to achieve through manual processing at 30--60 minutes per deed.

\paragraph{Comparative Analysis Across Jurisdictions.}
The standardized database schema and documented methodology enable consistent covenant mapping across multiple Massachusetts counties. This comparability supports research questions about:
\begin{itemize}
    \item Variation in covenant prevalence by municipality type (urban vs. suburban)
    \item Relationship between local political context and covenant adoption
    \item Influence of regional real estate industry practices
\end{itemize}

\paragraph{Longitudinal Legal Evolution Studies.}
The extracted covenant language corpus enables computational text analysis of linguistic patterns over time, revealing how legal framing adapted to evolving case law and social norms. This application demonstrates how automation transforms qualitative historical sources into quantitatively analyzable datasets.

\subsection{Deployment with MassHousing}

The pipeline is being packaged for deployment with MassHousing, the Commonwealth's affordable housing finance agency. MassHousing requires precise geographic data to validate special purpose credit programs targeting historically discriminated communities, as authorized under fair lending regulations.

\paragraph{Policy Application Context.}
Federal fair lending law permits ``special purpose credit programs'' that provide preferential terms to groups who have historically faced discrimination. However, implementing such programs requires documented evidence of historical discrimination in specific geographic areas. Covenant mapping provides this evidence by demonstrating systematic residential segregation at neighborhood level.

\paragraph{Technical Integration Requirements.}
Deployment involves:
\begin{itemize}
    \item Batch processing interface for processing deed datasets
    \item Confidence score filtering to support different risk tolerance levels
    \item Export functionality to GIS formats (GeoJSON, Shapefile) for integration with MassHousing's existing spatial analysis tools
    \item Documentation for non-technical policy staff
\end{itemize}

\paragraph{Use Case Example.}
A proposed credit program might target census tracts where covenant mapping demonstrates historical exclusion. The pipeline's confidence scores enable MassHousing to balance geographic coverage (accepting lower confidence thresholds) against evidence strength (requiring higher confidence for policy justification). Deeds with confidence scores below 0.5 undergo manual verification before inclusion in policy analyses.

\subsection{Broader Applicability}

\paragraph{Adaptation to Other Massachusetts Counties.}
The pipeline's modular design enables adaptation to other Massachusetts counties with minimal modification. Key adaptation points include:
\begin{itemize}
    \item Registry URLs (different counties use different MassLand Records interfaces)
    \item Historical town name mappings (gazetteer updates for county-specific subdivisions)
    \item Plan book indexing conventions (some registries use different numbering systems)
\end{itemize}

Initial testing on a small Suffolk County sample (10 deeds) yielded 70\% accuracy, suggesting reasonable generalizability within Massachusetts.

\paragraph{Limitations for Out-of-State Adaptation.}
The reliance on MassLand Records web scraping limits direct transferability to other states. However, the general pipeline architecture---OCR, entity extraction, geocoding, validation---remains applicable. States with centralized historical map databases (similar to Santa Clara County's ArcGIS system) would likely achieve higher accuracy than Massachusetts by replacing the web scraping step with direct georeferenced plan book matching.

\paragraph{Open Source Value.}
By releasing the pipeline as open source with comprehensive documentation, we enable other covenant mapping projects to:
\begin{itemize}
    \item Adapt components to their local infrastructure
    \item Learn from our validation methodology
    \item Contribute improvements back to the shared codebase
\end{itemize}

This collaborative approach accelerates covenant documentation efforts nationwide, supporting national covenant mapping initiatives.


% ============================================
% 3.5 Summary
% ============================================
\section{Summary}

This chapter demonstrated a practical document processing pipeline achieving 64.9\% complete geolocation accuracy on 111 validation deeds from a larger corpus of 569 historical records from Northern Middlesex County. The automated system processes deeds in 20 seconds each---a 90--180$\times$ speedup over manual methods---while maintaining neighborhood-level geographic precision suitable for policy analysis and historical research.

Key findings include:

\begin{enumerate}
    \item \textbf{Technical Feasibility}: Automated covenant geolocation is achievable even in decentralized registry environments through combining OCR, LLM-based extraction, web scraping, and multi-candidate geocoding.
    \item \textbf{Systematic Discrimination Patterns}: Geographic clustering (47\% of covenants in Varnum Town subdivision) and identical language across consecutive lot deeds demonstrate developer-level policies rather than individual discriminatory decisions.
    \item \textbf{Temporal Concentration}: Covenant usage peaked in the 1920s (>60\% of sample), coinciding with suburban expansion and legal precedents establishing covenant enforceability.
    \item \textbf{Scalability Value}: The 90--180$\times$ processing speedup enables documentation of thousands rather than hundreds of covenants, fundamentally changing the scope of achievable historical research.
\end{enumerate}

The pipeline's release as open-source software and deployment with MassHousing represents a tangible contribution to urban planning research infrastructure, providing both technical tools for researchers and evidentiary support for remedial policy programs.

The findings from this case study motivate the technical investigation in Chapter~\ref{ch:graph-rag}: given extracted spatio-temporal data about historical property records, how can retrieval systems effectively answer complex multi-hop queries linking geographic locations, temporal patterns, and discriminatory practices? The structured data produced by this pipeline becomes the foundation for evaluating whether graph-based knowledge representations offer advantages over traditional vector retrieval for spatio-temporal reasoning tasks.